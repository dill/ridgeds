% Strategies for correlated covariates in distance sampling
% David Lawrence Miller
% CREEM, University of St Andrews



```{r knitr-setup, include=FALSE}
knitr::opts_chunk$set(cache=TRUE)
```

## Covariates in distance sampling

  - CDS: $\mathbb{P}(\text{observing an object})$ depends on distance
  - MCDS: what about other factors?
    - per animal (sex, size,...)
    - environmental effects (weather, time of day, habitat,...)
    - observer effects (individual, team, pilot,...)
    - (group size -- not addressed here)

\includegraphics[width=\textwidth]{ants-nesthab-2.pdf}


## Detection functions

  - Models of the form

$$
g(x;\boldsymbol{\theta},z_1, \ldots, z_J) = \mathbb{P}(\text{detected}| \text{observed } x, z_1, \ldots, z_J)
$$

  - distances $x$
  - estimate parameters $\boldsymbol{\theta}$
  - covariates $z_1, \ldots, z_J$, that affect detection
  - covariates enter model via scale parameter:

$$
\sigma(z_1, \ldots, z_J) = \exp(\beta_0 + \sum_j z_j \beta_j)
$$

## Constraints and particulars

  - $g$ has fixed functional form
  - usually <5 covariates 
  - covariates independent from distance (in population)
  - inference on likelihood *conditional* on observed covariates

\includegraphics[width=\textwidth]{some-dfs.png}

## Motivating example: AK black bears

  * Black bear data from Alaska
  * 301 aerial observations
  * 3 covariates:
    - search distance
    - % foliage cover
    - % snow cover

\includegraphics[width=\textwidth]{bearinsnow.jpg}

## What can go wrong?

  - from linear model literature:
    * fitting problems
    * prediction fine
    * high(er) variance
    * non-interpretable covariates
  - important for DS:
    * fitted values ($\hat{p_i}(z_1,\ldots,z_J)$) important
    * rarely "predict"
    * variance important
    * covariates are nuisance


## Simulated example

\begin{columns}[T] % align columns
\begin{column}{.52\textwidth}
\begin{itemize}
  \item half-normal detection function $\exp\left(\frac{-x^2}{2\sigma(z_1,\ldots,z_J)^2}\right)$
  \item $z_1 \sim \text{beta}(0.1,0.4)$
  \item $z_2, z_3$ generated to be correlated with $z_1$
  \item fitted:
  \begin{itemize}
    \item $\sigma_1 = \exp(\beta_0 + z_1 \beta_1)$
    \item $\sigma_{12} = \exp(\beta_0 + z_1\beta_1+ z_2\beta_23$
    \item $\sigma_{123} = \exp(\beta_0 + z_1\beta_1 + z_2\beta_2 + z_3\beta_3)$
  \end{itemize}
  \item select model by AIC
  \item $\sim$90 samples per realisation
\end{itemize}
\end{column}%
\hfill%
\begin{column}{.48\textwidth}
\includegraphics[width=1.1\textwidth]{sim-df.pdf}
\end{column}%
\end{columns}


## Simulated example - $\text{Var}(\hat{p})$ 

```{r setup, include=FALSE}
options(stingsAsFactors=FALSE)
library(ggplot2)
library(plyr)
big.res <- read.csv("../covcor/covcor-wisp-smallp-PCA.csv")
results <- as.data.frame(big.res)
results <- results[,-1]
names(results) <- c("sim","N","model","corr","Ncovered","parameter","value")
# remove the half-normal only model
results <- subset(results, model!="hn")
# simplify the model labels
results$model <- sub("hn\\+","",results$model)
results$model <- gsub("cov","",results$model)
results$model <- sub("PCA","PCA ",results$model)
# remove the PCA 1+2+3 model, as it's equivalent to 1+2+3
results <- subset(results, model!="PCA 1+2+3")
```

```{r plotnopca, include=FALSE, fig.width=4.5, fig.height=3, fig.cap="",dpi=120}
results.noPCA <- results[!grepl("PCA",results$model),]
results.noPCA <- results.noPCA[results.noPCA$N==1000,]

varp <- results.noPCA[results.noPCA$parameter=="varp",]
pvar <- ggplot(varp)
pvar <- pvar + geom_boxplot(aes(x=model,y=value))
pvar <- pvar + facet_grid(.~corr,labeller = label_bquote(rho == .(x)))
pvar <- pvar + ylab("variance")
print(pvar)
```

\includegraphics[width=\textwidth]{figure/plotnopca.png}


## Simulated example - bias in $\hat{p}$ 

```{r plotnopca-bias, include=FALSE, fig.width=4.5, fig.height=3, fig.cap="",dpi=120}
pbias_f <- function(x){
  est.p <- x$value[x$parameter=="p"]
  true.p <- x$value[x$parameter=="n"]/x$N[1]

  pdiff <- (est.p-true.p)/true.p
  return(pdiff)
}

pbias <- ddply(results.noPCA,.(sim,corr,model), pbias_f)

pbias$label <- pbias$model
p <- ggplot(pbias)
p <- p + geom_boxplot(aes(x=label,y=V1))
p <- p + facet_grid(.~corr,labeller = label_bquote(rho == .(x)))
p <- p + ylab("relative bias")
p <- p + xlab("model")
print(p)
```

\includegraphics[width=\textwidth]{figure/plotnopca-bias.png}



## What can we do?

  - Obvious possibilities from linear modelling:
    * Ridge regression
    * Lasso
    * PCA
  - Shrinkage methods require estimate shrinkage!
    * change in fitting procedure


## Simple solutions

  - Principle components
    * fast, simple, most people know about it
    * "derived" covariates -- no change in fitting procedure
    * *only* covariates, **not** distance
  - standardise covariates $\Rightarrow \mathcal{Z}$
  - take $\mathcal{Z}^\text{T}\mathcal{Z} = U^\text{T}\Lambda U$
  - new covariates $z_j^* = \mathcal{Z}\mathbf{u}_j$
  - select new PCA covariates in order
    * using all gives same fit as no-PCA model


## Simulation revisit - $\text{Var}(\hat{p})$ 

```{r plotpca, include=FALSE, fig.width=7, fig.height=4, fig.cap="",dpi=120,plot=TRUE}
results.PCA <- results[results$N==1000,]
results.PCA$model  <- sub("PCA","PCA\n",results.PCA$model)

varp <-results.PCA[results.PCA$parameter=="varp",]
pv <- ggplot(varp)
pv <- pv + geom_boxplot(aes(x=model,y=value))
pv <- pv + facet_grid(.~corr,labeller = label_bquote(rho == .(x)))
pv <- pv + ylab("variance")
print(pv)
```

\includegraphics[width=\textwidth]{figure/plotpca.png}


## Simulation revisit - AIC

```{r plot-aic-winners, include=FALSE, fig.width=7, fig.height=4, fig.cap="",dpi=120,plot=TRUE}
aicres <- results[results$parameter=="aic",]
aicres <- aicres[aicres$N==1000,]
aicres$model  <- sub("PCA","PCA\n",aicres$model)

aic.winner <- function(x){
  if(!all(is.na(x$value))){
    return(as.character(x$model[which.min(x$value)]))
  }else{
    return(NA)
  }
}

aicw <- ddply(aicres,.(sim,corr),aic.winner)

pd <- ggplot(aicw)
pd <- pd + geom_histogram(aes(V1))#,binwidth=0.01)
pd <- pd + xlab("Model")
pd <- pd + facet_wrap(~corr,ncol=3)
print(pd)
```

\includegraphics[width=\textwidth]{figure/plot-aic-winners.png}


## Black bears - results

  * 3 observed covariates:
    - 3 PC (full model) better than 2 in AIC
  * 1 dummy covariate
    - correlated with search distance ($\rho=0.9$)
    - 3 PC model better AIC than 2 or 1
    - 3 PC model give $\sim$ 10% saving in variance
  * for both models, small changes in $\hat{p}$   

\hfill \includegraphics[width=0.5\textwidth]{mybb.jpg}


```{r results-noextra-hidden, include=FALSE}
#             p       p.se      AIC
# allcov 0.3523942 0.02316806 3390.532
# pca1   0.4326059 0.01961730 3468.661
# pca2   0.3577041 0.02280119 3393.454 <<<
# pca3   0.3523930 0.02316801 3390.532
```

```{r results-extra-hidden, include=FALSE}
#                  p       p.se      AIC
# allcov   0.3521192 0.02338857 3392.346
# allcov.t 0.3523942 0.02316806 3390.532
# pca1     0.3778260 0.02104195 3411.877 
# pca2     0.3741386 0.02106807 3409.679
# pca3     0.3690302 0.02153997 3406.481 <<<
# pca4     0.3521192 0.02338811 3392.346
```

```{r bbres, include=FALSE}
#$variance
#         [,1]
#[1,] 2672.683
#
#$partial
#            [,1]
#[1,] -777.821315
#[2,]  505.710048
#[3,] -120.590367
#[4,]    9.677448
#[5,]  438.831832
#
#
#D(5)>
#         [,1]
#[1,] 5092.582
#
#D(5)> sum((1-model$fitted)/model$fitted^2)
#[1] 2419.899
```


## What's going on?

In terms of $\hat{N_c}$:

\begin{align*}
\text{var}(\hat{N_c}) &= w^2 \sum_i \hat{f}(0|\mathbf{z})^2 - \hat{N_c} + \left[\frac{\partial N_c}{\partial \theta}\right]^\text{T} H^{-1} \left[\frac{\partial N_c}{\partial \theta}\right]\\
% &= \sum_i \left[\left(\frac{1}{\hat{p_i}}\right)^2 - \frac{1}{\hat{p_i}}\right] + \left[\frac{\partial N_c}{\partial \theta}\right]^\text{T} H^{-1} \left[\frac{\partial N_c}{\partial \theta}\right]
&= \sum_i \frac{1-\hat{p}_i}{\hat{p}_i^2} + \left[\frac{\partial \hat{N_c}}{\partial \hat{\theta}}\right]^\text{T} H^{-1} \left[\frac{\partial \hat{N_c}}{\partial \hat{\theta}}\right]
\end{align*}

first term dominates.

## Further work

  * what about other situations?
    - hazard-rate, etc. detection functions
    - factor covariates
  * is it ever "bad" to do this?
  * is ridge/lasso more "efficient"?
  * is anyone here doing "large" analyses?

<br/>

<br/>

<p align="center">**Talk available at: `http://converged.yt/talks/dscorrcovar.pdf`**</p>






```{r simres, include=FALSE}
#$variance
#         [,1]
#[1,] 1744.201
#
#$partial
#          [,1]
#[1,] -419.6683
#[2,]  329.7366
#[3,]  230.0472
#
#
#D(27)>
#         [,1]
#[1,] 3562.469
#
#D(27)> sum((1-model$fitted)/model$fitted^2)
#[1] 1818.268
#
#############################################
#D(5)>
#$variance
#         [,1]
#[1,] 1096.765
#
#$partial
#          [,1]
#[1,] -400.7523
#[2,]  298.2376
#
#
#D(5)>
#         [,1]
#[1,] 3297.192
#
#sum((1-model$fitted)/model$fitted^2)
#[1] 2200.427
#
#############################################
#$variance
#         [,1]
#[1,] 1387.289
#
#$partial
#          [,1]
#[1,] -401.8247
#[2,]  293.3195
#[3,]  202.1095
#[4,]  231.6329
#
#
#D(5)>
#         [,1]
#[1,] 3574.138
#
#sum((1-model$fitted)/model$fitted^2)
#[1] 2186.848
```



